{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWWphFKtvO6IuD6x7cpm1r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JpChii/ML-Projects/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay let's do this, Learn some torch.\n",
        "\n",
        "> 30th April 9:40 IST"
      ],
      "metadata": {
        "id": "MNRLEBVsogwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "L9o7IUbspyho"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Checking GPU and cuda support\n",
        " torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ed4KA4RrrJw",
        "outputId": "c2e82ca1-bfcf-46b1-d44c-1385e440b5a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Tensor Basics\n",
        "\n",
        "In pytorch everything is based tensors."
      ],
      "metadata": {
        "id": "_imB9y76r1FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an empty tensor\n",
        "x = torch.empty(3, 2, 2, 3) # tf.constant()\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TjfUF43sRqK",
        "outputId": "d3215d7b-81cc-4227-beb8-cfea465a62cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 3.5816e-35,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.4013e-45,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 3.7210e-35,  0.0000e+00,  1.6732e-35],\n",
            "          [ 0.0000e+00, -2.4286e-30,  4.5874e-41]],\n",
            "\n",
            "         [[ 2.8026e-45,  0.0000e+00,  2.8026e-45],\n",
            "          [ 0.0000e+00,  4.2039e-45,  0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 4.2039e-45,  0.0000e+00,  1.4013e-45],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Random Tensor\n",
        "x = torch.rand(2, 2)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxUMKOiNsbq6",
        "outputId": "08676dff-f346-4728-9f20-6746ebcd7a0c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6204, 0.0075],\n",
            "        [0.5981, 0.6651]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zeros tensor\n",
        "x = torch.zeros(2, 2)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCcklTBnsyki",
        "outputId": "67862ba7-8683-49f3-edd0-7cd04dc9edf7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ones tensor\n",
        "x = torch.ones(2,2, dtype=torch.float16)\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "print(x.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQyIzXvHyY6j",
        "outputId": "dbc1a0e3-231c-40e2-b87b-40b643b7ec54"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], dtype=torch.float16)\n",
            "torch.float16\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensor from python list\n",
        "x = torch.tensor([1,2])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCGiav1mykgJ",
        "outputId": "4994e480-41c1-4022-f9f3-37734d9b9ebe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic operations\n",
        "x = torch.rand(2, 2)\n",
        "y = torch.rand(2, 2)\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9PE86BKzRuN",
        "outputId": "dbbc3e18-03c2-4d33-ffcb-2e27352111c8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3010, 0.4266],\n",
            "        [0.5522, 0.8659]])\n",
            "tensor([[0.6596, 0.6837],\n",
            "        [0.0585, 0.6424]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.add(x, y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ch6ld6Azagv",
        "outputId": "998ad40d-31db-4d0d-e806-5615d09bc7a4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9605, 1.1103],\n",
            "        [0.6107, 1.5083]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In place addition\n",
        "y.add_(x) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r0Z8ooqzgDr",
        "outputId": "58c88594-f1f6-470b-cb95-e4ff5b1147cd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9605, 1.1103],\n",
              "        [0.6107, 1.5083]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "print(x[:, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PnK2RfQz6a5",
        "outputId": "8e039511-6bb4-4023-ac32-967432788c6d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7905, 0.1205, 0.1779],\n",
            "        [0.1668, 0.7189, 0.0564],\n",
            "        [0.5438, 0.8737, 0.2739],\n",
            "        [0.7827, 0.5072, 0.9777],\n",
            "        [0.4128, 0.2837, 0.5488]])\n",
            "tensor([0.7905, 0.1668, 0.5438, 0.7827, 0.4128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF-UbKw-0LIf",
        "outputId": "8f1300d1-3461-45cc-ed92-ab4be88370ad"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1668, 0.7189, 0.0564])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaing a tensor\n",
        "x = torch.rand(4, 4)\n",
        "print(x)\n",
        "y = x.view(16)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7jH6Iee0SR7",
        "outputId": "dcc49621-cfed-4732-e9fd-d3cf3279b029"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6978, 0.8248, 0.8967, 0.2190],\n",
            "        [0.9712, 0.4313, 0.0503, 0.6076],\n",
            "        [0.5150, 0.5144, 0.3651, 0.3434],\n",
            "        [0.1204, 0.7721, 0.1049, 0.0760]])\n",
            "tensor([0.6978, 0.8248, 0.8967, 0.2190, 0.9712, 0.4313, 0.0503, 0.6076, 0.5150,\n",
            "        0.5144, 0.3651, 0.3434, 0.1204, 0.7721, 0.1049, 0.0760])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy to torch and vice versa\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg9ZIeKZ0lS5",
        "outputId": "5922907f-307d-4831-9f27-55d124397521"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.add_(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwTmpBTW1DL1",
        "outputId": "c5fbed03-2106-45da-961e-f397a3255acb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In cpu a nd b both point to same memory location\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8iwtrdz1RjZ",
        "outputId": "26208583-80a1-4f15-e82f-6681f9b907ca"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.ones(5)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(type(b))\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9EoYXcJ1S_z",
        "outputId": "b0747447-0204-4884-a58f-f27f40cb0450"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "<class 'torch.Tensor'>\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a += 1\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-AiCiEy1h9u",
        "outputId": "b5e03be1-3790-408b-ef89-f38c7b85436b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Switched to GPU to check the above scenario\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  x = torch.ones(5, device=device)\n",
        "  y = torch.ones(5)\n",
        "  Y = y.to(device)\n",
        "  z = x + Y"
      ],
      "metadata": {
        "id": "nJvNu05g1our"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyF4zV1i2VmK",
        "outputId": "6a97e495-2ecf-4443-fbf9-06c08de4a55b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = z.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "oT0Mt95E2sQi",
        "outputId": "df7e9994-4c03-40a1-edc2-9496ebaa8177"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7b23e7bfeee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy doesn't work with GPU, since we created the tensor woth gpu\n",
        "z = z.to(\"cpu\")\n",
        "z.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQzozCbp2aHE",
        "outputId": "7efd49f2-16ca-426b-fbcd-8227daead175"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., 2., 2.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5, requires_grad=True) # This will tell pytorch that gradients needs to be calculated for this tensor later in the optimization step\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFiFFeod2pj7",
        "outputId": "3bf197e8-c47c-4543-96f8-a94117396597"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Whenever we've a variable that needs to optimized, `requires_grad=True`"
      ],
      "metadata": {
        "id": "dh4rCZ403Eia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorBasics Summary\n",
        "\n",
        "1. Similar to numpy\n",
        "2. view - reshape\n",
        "3. torch.math operations\n",
        "4. variable.math_operations_ - inplace mathametical operation\n",
        "5. requires_grad"
      ],
      "metadata": {
        "id": "iMaoTN-w3iG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autograd\n",
        "\n",
        "Package in pytorch to calculate graidents, Gradient computation.\n",
        "Autograd provides all the stuff with Autograd"
      ],
      "metadata": {
        "id": "I1mi5g4R3cz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuxkxX8b4B3i",
        "outputId": "30e4cee0-a64b-4d5f-bd67-3dbf1bcd3c4a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2.1019, -0.8781, -0.3495])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Later we need to calculate the gradient of some function with respect to x intialize the variable with requires_grad\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GYBKhdS4EqL",
        "outputId": "58c3d3ef-4eb6-4b7a-97c5-e8c11e351c50"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0129,  1.6865, -0.4534], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x + 2"
      ],
      "metadata": {
        "id": "VsoHAhVl4Qip"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y) # In the output we can see a gradient function, since the operation is addition, grad_dn is AddBackward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCIbornv4Yfo",
        "outputId": "4f8a9d12-784d-4693-de2e-9e490053bed8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.0129, 3.6865, 1.5466], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y*y*2 # For multiplication\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LqGT04g4rBg",
        "outputId": "bb2d21d2-53db-47ce-8e1f-8051b14ae3c4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8.1032, 27.1808,  4.7840], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = z.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgo3qMBF41T6",
        "outputId": "dab40319-ec7d-4ab7-be19-a394ab0493fd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(13.3560, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To calculate the gradient just call backward\n",
        "z.backward() # dz/dx\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB1MgmXL5FiW",
        "outputId": "31d36507-dbaf-4057-c88c-e8377d60f2cd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.6838, 4.9154, 2.0621])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient calculation works for a scalar, what happens with a vector\n",
        "x = torch.randn(2, requires_grad=True)\n",
        "y = x + 2\n",
        "z = y*y*2\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "orXYYvLz5Npl",
        "outputId": "49390898-def0-41b5-91e2-3aecb02e8c0d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-2d361abbe8f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This wont't work, since gradient calculation is a jacobian vector multiplication. We need to pass a vector"
      ],
      "metadata": {
        "id": "i6Np96Qv6chH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing random weights\n",
        "v = torch.tensor([0.1,1.0], dtype=torch.float32)\n",
        "z.backward(v)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0v6MO9a6jkL",
        "outputId": "c229151f-1b25-4ede-fea7-9d77650f1939"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0924, 11.4316])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prevent pytorch from tracking the history and grad_fn attribute.\n",
        "Updating the weights shouldn't be a part of gradient computation which is gradien_fn.\n",
        "Three options to avoid this are\n",
        "1. x.requires_grad_(false)\n",
        "2. x.detach()\n",
        "3. with torch.no_grad():"
      ],
      "metadata": {
        "id": "VVFEgumi6rJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(False)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx8SnsTr7KpU",
        "outputId": "143cffb2-f423-420e-afde-1fee6e1b4d64"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.7690,  0.8579])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(True)\n",
        "y = x.detach()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brIn3lz48TtL",
        "outputId": "1566fc9b-a1e3-4a65-a977-6229d43033ad"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.7690,  0.8579])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y = x + 2\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxaMy4h68Zc3",
        "outputId": "7ab357f6-48b0-4fa9-aacd-18953b85406f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2310, 2.8579])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA7seqHq8itw",
        "outputId": "38d2a1df-190a-477a-b66a-cd12742c4062"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2310, 2.8579], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whenver `.backward()` function is called gradient for the tensor will be calculated and accmulated in `grad`"
      ],
      "metadata": {
        "id": "J4ls0obd8nX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(3):\n",
        "  model_output = (weights * 3).sum()\n",
        "\n",
        "  # Calculating gradient\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "\n",
        "  # Resetting weights for each epoch\n",
        "  weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be-VIeB_9BR5",
        "outputId": "977fbe9a-9259-43d5-da0e-af2a7a26c81d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autograd summary:\n",
        "\n",
        "* Whenever gradient needs to be calculated for a tensor `requires_grad=True`\n",
        "* To calculate the gradient by calling `.backward()`\n",
        "* Before next iteration or epoch empty the gradients\n",
        "* Prevent weigh calculation from gradient computation using `detach(), torch.no_grad()`"
      ],
      "metadata": {
        "id": "gPaVgtZh9T0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropogation\n",
        "\n",
        "* Gradient is calculated using a chain role from output to input in backward direction\n",
        "* Computation graph - for every operation we do with tensors, pytorch will create a graph \n",
        "\n",
        "*Whole concept consists of three steps:*\n",
        "\n",
        "1. Forward pass: Compute loss\n",
        "2. Each node - compute local gradients\n",
        "3. Backward pass: Compute dLoss / dWeights using the chain rule"
      ],
      "metadata": {
        "id": "0-m0xvzOBBR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "w = torch.tensor(1.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "_b2YhWk7BDKJ"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass and compute the loss\n",
        "y_hat = w * x\n",
        "loss = (y_hat - y) ** 2\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDzvw9jqEMFh",
        "outputId": "d7d6428b-3a49-42ba-f2eb-75d438c09f12"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward pass\n",
        "# Pytorch automatically computes locaal gradient and backward pass\n",
        "loss.backward()\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKwqwsRxFkGh",
        "outputId": "a912b752-2a31-48e5-dd4f-5d8ccf0227f6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backpropogation summary\n",
        "\n",
        "1. forward pass\n",
        "2. compute local gradients\n",
        "3. backward pass"
      ],
      "metadata": {
        "id": "tanVEcaSF36m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## linear regression\n",
        "\n",
        "1. Prediction: Manually - PyTorch Model\n",
        "2. Gradients computation: Manually - Autograd\n",
        "3. Loss computation: Manually - PyTorch Loss\n",
        "4. Parameter updates: Manually - PyTorch Optimizer\n",
        "\n",
        "### All manual"
      ],
      "metadata": {
        "id": "pn6OV_E8FuLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f = w * x\n",
        "# f = 2 * x\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)"
      ],
      "metadata": {
        "id": "UjxgsI8OGLs5"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize initial weight\n",
        "w = 0.0"
      ],
      "metadata": {
        "id": "PYE1E9_BI2mj"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "  return ((y_pred - y) ** 2).mean()\n",
        "\n",
        "# Gradient\n",
        "# MSE = 1/N * (w*x - y) ** 2\n",
        "# MSE = 1/n_samples * (pred - truth) ** 2\n",
        "# dJ/dw = 1/N 2x (w*x) - y\n",
        "def gradient(x, y, y_pred):\n",
        "  return np.dot(2*x, y_pred - y).mean()"
      ],
      "metadata": {
        "id": "JO1MI7M_I54a"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Prediction before training: f(5) = {forward(5):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asCrN2GWJq88",
        "outputId": "65ad6d0b-a6cd-4dcd-9bf1-87a9e4a95cff"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 10"
      ],
      "metadata": {
        "id": "3rNuKS65Jz21"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward_pass\n",
        "  y_pred = forward(X)\n",
        "  # Loss\n",
        "  l = loss(Y, y_pred)\n",
        "  # gradients\n",
        "  dw = gradient(X, Y, y_pred)\n",
        "\n",
        "  # Update weights\n",
        "  w -= learning_rate * dw\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    print(f\"Epoch: {epoch + 1}, weight: {w:.3f}, loss: {l:.8f}\")\n",
        "\n",
        "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yYN_gIyJ8mb",
        "outputId": "17f56e13-10a5-4cbd-da1a-122906b56536"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, weight: 1.200, loss: 30.00000000\n",
            "Epoch: 2, weight: 1.680, loss: 4.79999924\n",
            "Epoch: 3, weight: 1.872, loss: 0.76800019\n",
            "Epoch: 4, weight: 1.949, loss: 0.12288000\n",
            "Epoch: 5, weight: 1.980, loss: 0.01966083\n",
            "Epoch: 6, weight: 1.992, loss: 0.00314574\n",
            "Epoch: 7, weight: 1.997, loss: 0.00050331\n",
            "Epoch: 8, weight: 1.999, loss: 0.00008053\n",
            "Epoch: 9, weight: 1.999, loss: 0.00001288\n",
            "Epoch: 10, weight: 2.000, loss: 0.00000206\n",
            "Prediction after training: f(5) = 9.999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "weights is `10` becaue gradient is calculate as 2* so for 5 epochs 5 *2 = 10"
      ],
      "metadata": {
        "id": "mddND1PPKxPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's impliment all the step using pytorch"
      ],
      "metadata": {
        "id": "LSTnqwLBNpNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "Y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # Replacing gradient calculation with pytorch\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # Update weights\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "\n",
        "  # Zero gradients\n",
        "  w.grad.zero_()\n",
        "\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    print(f\"Epoch: {epoch + 1}, weight: {w:.3f}, loss: {l:.8f}\")\n",
        "\n",
        "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gvoEBnDNthB",
        "outputId": "1ad1cfc9-b652-482a-bdb6-3db7cbcaa9f4"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, weight: 0.300, loss: 30.00000000\n",
            "Epoch: 2, weight: 0.555, loss: 21.67499924\n",
            "Epoch: 3, weight: 0.772, loss: 15.66018772\n",
            "Epoch: 4, weight: 0.956, loss: 11.31448650\n",
            "Epoch: 5, weight: 1.113, loss: 8.17471695\n",
            "Epoch: 6, weight: 1.246, loss: 5.90623236\n",
            "Epoch: 7, weight: 1.359, loss: 4.26725292\n",
            "Epoch: 8, weight: 1.455, loss: 3.08308983\n",
            "Epoch: 9, weight: 1.537, loss: 2.22753215\n",
            "Epoch: 10, weight: 1.606, loss: 1.60939169\n",
            "Prediction after training: f(5) = 8.031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient computation is moved to Autograd, next loss and paramter updation"
      ],
      "metadata": {
        "id": "uiw5oV-iPAF-"
      }
    }
  ]
}