{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recurrent-Neural-Networks-with-Keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMlFidzfsf4FvRLrOh+L+C2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JpChii/ML-Projects/blob/main/Recurrent_Neural_Networks_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPw4Y06FLYV4"
      },
      "source": [
        "# Recurrent Neural Networks\n",
        "\n",
        "Recurrent neural networks (RNN) are a class of neural networks that is powerful for modeling sequence data such as time series or natural language.\n",
        "    \n",
        "RNN's have a internal `for loop` to iterate over timestamps of sequence data. The RNN's have an internal state that encodes information about the timestamps it has seen.\n",
        "\n",
        "Since `TesnorFlow` is my current primary framework for deep modelling, i'll use that in this blog.\n",
        "\n",
        "The `Keras RNN API` provides us with `layers.RNN`, `layers.LSTM` and `layers.GRU` for ease of use. The` internal for loop` can be customized and used with `layers.RNN` for loop itself offering ease of customization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMEGagMaLw0i"
      },
      "source": [
        "# Importing\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjsjxhIhL-EO"
      },
      "source": [
        "## Built-in RNN layers\n",
        "\n",
        "1. keras.layers.SimpleRNN\n",
        "2. keras.layers.GRU\n",
        "3. keras.layers.LSTM\n",
        "\n",
        "They have many useful features, some of them are listed below,\n",
        "\n",
        "* Recurrent dropout, via the `dropout` and `recurrent_dropout` arguments\n",
        "* Process input sequence in reverse, via `go_backwords` argument\n",
        "* Loop unrolling(can lead to large spedup when processig short sequences on CPU), via the unroll argument."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgrS2yylMNtj"
      },
      "source": [
        "## Output and states\n",
        "By default, output of a RNNlayer contains a single vector per sample. This vector is the RNN cell outut corresponding to the last timestamp, containing information about the entire sequence of inputs. The output shape will be `(batch_size,units)`, units is the number of units passed to RNN layer.\n",
        "\n",
        "RNN layer can also return the entire sequence of output across the timestap(one vector per timestamp per sample). The output shape in this case will be `(batch_size, timesteps, units)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVcP2K4oN9mV",
        "outputId": "e0858eb4-e415-4078-bdb0-891a4986bbc1"
      },
      "source": [
        "# LEt's check out the above theory in a model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=1000,output_dim=64))\n",
        "\n",
        "# GRU with return sequence true\n",
        "model.add(layers.GRU(256, return_sequences=True))\n",
        "\n",
        "# SimpleRNN \n",
        "model.add(layers.SimpleRNN(128))\n",
        "model.add(layers.Dense(10))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 256)         247296    \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 128)               49280     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 361,866\n",
            "Trainable params: 361,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpkcyNgtOrgm",
        "outputId": "68ff0d12-d1a0-41f9-a3bd-52a89edaa2d6"
      },
      "source": [
        "3 * (256 * (256+64+1) + 256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "247296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhBVCHuZPSmZ"
      },
      "source": [
        "Calculating GRU's trainable parametes:\n",
        "\n",
        "```\n",
        "number of functional units * (hidden_units * (hidden_units + inputs + bias) + hidden units)\n",
        "```\n",
        "\n",
        "In the previous cell it's\n",
        "\n",
        "```\n",
        "3 * (64 * (64 + 128 + 1) + 64) = 37248\n",
        "```\n",
        "\n",
        "If we notice the number of trainable parameters has reduced in GRU compared to LSTM. Let's compare the metrics with baseline next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObHNqwqXPYiD"
      },
      "source": [
        "In addition, RNN layer can return its final internal state(s). The returned states can be used to reusume the RNN execution later or to initialize another RNN. This setting is commonly used in the encoder-decoder sequence-to-sequene moel, where the encoder final state is used as the initial state of the decoder.\n",
        "\n",
        "To configure a RNN layer to return it;s internal states, set `return_state` to `true` when creating the layer. `LSTM` has `2` states and `GRU` has `1` state.\n",
        "\n",
        "And the encoder and decoder RNN layer must have the same number of units. And add `initial_state` to `internal state(s)` in decoding layer.\n",
        "\n",
        "Let's write the code for this below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF7c_j7HRMlk",
        "outputId": "31d2938e-528c-47b6-f7d2-9a629d9a856c"
      },
      "source": [
        "encoder_vocab = 1000\n",
        "decoder_vocab = 2000\n",
        "\n",
        "encoder_input = layers.Input(shape=(None,))\n",
        "encoder_embedded = layers.Embedding(input_dim=encoder_vocab,\n",
        "                                 output_dim=64)(encoder_input)\n",
        "\n",
        "# Return states in addition to output\n",
        "output, state_h, state_c = layers.LSTM(64, return_state=True)(encoder_embedded)\n",
        "\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_input = layers.Input(shape=(None,))\n",
        "decoder_embedded = layers.Embedding(input_dim=decoder_vocab,\n",
        "                                    output_dim=64)(decoder_input)\n",
        "\n",
        "# Pass the 2 states to a new decoder  layers\n",
        "decoder_output = layers.LSTM(64)(decoder_embedded, initial_state=encoder_state)\n",
        "output = layers.Dense(10)(decoder_output)\n",
        "\n",
        "model = keras.Model([encoder_input,decoder_input], output)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 64)     64000       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 64)     128000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 64), (None,  33024       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 64)           33024       embedding_2[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 258,698\n",
            "Trainable params: 258,698\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YLkdOsMSn-X"
      },
      "source": [
        "## RNN layers and RNN cells\n",
        "\n",
        "In addition to built-in RNN layers, there are also RNN cells provided by RNN API. Unlike RNN layers, cells can process only process a single timestamp.\n",
        "\n",
        "`LSTM cell` wrapped in a `RNN layer` is equivalent to `LSTM layer`. But built-in `GRU` and `LSTM` layers enable the use of CuDNN and may see a better performance.\n",
        "\n",
        "There are three built-in RNN cells, each of them corresponding to the matching RNN layer.\n",
        "\n",
        "* `keras.layers.SimpleRNNCell` for `SimpleRNN` layer\n",
        "* `keras.layers.GRUCell` for `GRU` layer\n",
        "* `keras.layers.LSTMCell` for `LSTM`layer\n",
        "\n",
        "This cell abdtraction, together with generic `RNN layer` makes it very easy to implement custom RNN architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDul7PNZVv7n"
      },
      "source": [
        "## Cross-batch statefulness\n",
        "\n",
        "RNN's state is resetted when a new batch arrives in(i.e get's resetted for new sample), every sample seen by the layers is assumed to be independent of past.\n",
        "\n",
        "If the sequences are long, possibly infinite. We can split the sequences and pass it to RNN without resetting the state using `stateful=True` parameter. This is called cross-batch statefulness.\n",
        "\n",
        "In this splitted batches should be of the same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq3kk7UrXO8I"
      },
      "source": [
        "# Implementaion of cross-batch statefulness\n",
        "paragraph1 = np.random.random((20,10,50)).astype(np.float32)\n",
        "paragraph2 = np.random.random((20,10,50)).astype(np.float32)\n",
        "paragraph3 = np.random.random((20,10,50)).astype(np.float32)\n",
        "\n",
        "lstm_layer = layers.LSTM(64, stateful=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU-lPU9TYHlA"
      },
      "source": [
        "output = lstm_layer(paragraph1)\n",
        "output = lstm_layer(paragraph2)\n",
        "output = lstm_layer(paragraph3)\n",
        "                    \n",
        "# reset_states() will reset the cached state to the original initial_state.\n",
        "# If no initial_state was provided, zero-states will be used by default.\n",
        "lstm_layer.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtv8VWHxY-U7"
      },
      "source": [
        "## RNN state reuse\n",
        "\n",
        "RNN layer's recorded states can be accessed in `layers.states` and can be used as `initial_state` for another layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVNKXg4tYcUe"
      },
      "source": [
        "#Getting recored state\n",
        "existin_state = lstm_layer.states\n",
        "\n",
        "# Initializing new layer with the above state\n",
        "new_lstm_layer = layers.LSTM(64)\n",
        "new_ouput = new_lstm_layer(paragraph3, initial_state=existin_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJqrPh01ZjgT"
      },
      "source": [
        "## Bidirectional RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIBHgjxfZ618"
      },
      "source": [
        "## Bidirectional RNNs\n",
        "\n",
        "For sequences other than time series(eg text), it is often the case RNN mode performs better when processing the sequence forwards and backwards.\n",
        "\n",
        "Read the text forward and sometimes reading it backwards gives beter understanding.\n",
        "\n",
        "`keras.layers.bidirectional` wrapper can be used for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufVJK6i3tK7_",
        "outputId": "38b98991-98cd-471a-9e1f-f9c9bc2f3f64"
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10))\n",
        ")\n",
        "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional (None, 5, 128)            38400     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 80,266\n",
            "Trainable params: 80,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp5LQXXgtmNr"
      },
      "source": [
        "Under the hood, Bidirectional will copy the RNN layer passed in, and flip the go_backwards field of the newly copied layer, so that it will process the inputs in reverse order.\n",
        "\n",
        "The output of the Bidirectional RNN will be, by default, the concatenation of the forward layer output and the backward layer output. If you need a different merging behavior, e.g. concatenation, change the merge_mode parameter in the Bidirectional wrapper constructor. For more details about Bidirectional, please check the API docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htW6A4Rbt5M0"
      },
      "source": [
        "## Performance Optimization and cuDNN kernels\n",
        "\n",
        "In TensorFlow 2.0 built-in LStm and GRU layers itself support CuDNN when GPU is available.\n",
        "\n",
        "CuDNN kernel is built with certain assumptions, meaning layer won't be able to use Cudnn if the defaults of the built-in LSTM or GRU layers are changed.\n",
        "\n",
        "[Constraints for LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM/)\n",
        "\n",
        "[Constraints for GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVqvcLgxu5OO"
      },
      "source": [
        "batch_size = 64\n",
        "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
        "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
        "input_dim = 28\n",
        "\n",
        "units = 64\n",
        "output_size = 10  # labels are from 0 to 9\n",
        "\n",
        "# Build the RNN model\n",
        "def build_model(allow_cudnn_kernel=True):\n",
        "    # CuDNN is only available at the layer level, and not at the cell level.\n",
        "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "    if allow_cudnn_kernel:\n",
        "        # The LSTM layer with default options uses CuDNN.\n",
        "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
        "    else:\n",
        "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
        "        lstm_layer = keras.layers.RNN(\n",
        "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
        "        )\n",
        "    model = keras.models.Sequential(\n",
        "        [\n",
        "            lstm_layer,\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(output_size),\n",
        "        ]\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_xUV7oTvQ5G",
        "outputId": "4afab687-0c79-4976-9b07-e6c81701d588"
      },
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "sample, sample_label = x_train[0], y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWEdk0P-vUHY",
        "outputId": "dc5f369a-6c27-4c5f-9e54-c353a13f08c6"
      },
      "source": [
        "# Build and fit the model\n",
        "model = build_model(allow_cudnn_kernel=True)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 9s 5ms/step - loss: 0.8934 - accuracy: 0.7147 - val_loss: 0.5061 - val_accuracy: 0.8374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe8de38bb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnLNvOuFvZWY",
        "outputId": "ed972016-035f-4ebf-cac9-f6daf6845450"
      },
      "source": [
        "noncudnn_model = build_model(allow_cudnn_kernel=False)\n",
        "noncudnn_model.set_weights(model.get_weights())\n",
        "noncudnn_model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "noncudnn_model.fit(\n",
        "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 41s 42ms/step - loss: 0.3973 - accuracy: 0.8776 - val_loss: 0.8967 - val_accuracy: 0.7093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe93b83af50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21y71tSlviEq",
        "outputId": "5a3f0aed-6490-4e78-e531-4a8de396e3d7"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-8da050de-e853-2142-1ff0-71451742bd71)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "W0c5osj0wQN6",
        "outputId": "a858ea1b-90dd-4a4b-9c88-3dd2c515d3de"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with tf.device(\"CPU:0\"):\n",
        "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
        "    cpu_model.set_weights(model.get_weights())\n",
        "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
        "    print(\n",
        "        \"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label)\n",
        "    )\n",
        "    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted result is: [3], target result is: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hyl3zYnwhzP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}