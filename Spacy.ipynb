{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgS6XDnYT+JYNWcSzVWHQn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JpChii/ML-Projects/blob/main/Spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Finding words, phrases, names, concepts\n",
        "\n",
        "Learn basics of text processing with spacy. Learn about the data structures, how to work with trained pipelines and how to use them to predict linguistic features in your text."
      ],
      "metadata": {
        "id": "VgjgT3RfLOuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import spacy\n",
        "import spacy"
      ],
      "metadata": {
        "id": "tLmAkDirPKNN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a blank English nlp object\n",
        "nlp = spacy.blank(\"en\")"
      ],
      "metadata": {
        "id": "fAwKuH-HPRPk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* NLP object contains the processing pipeline\n",
        "* Includes language-spaecific rules for tokenization etc"
      ],
      "metadata": {
        "id": "S-DAoeoRPmnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Doc object\n",
        "doc = nlp(\"Hello world!\")"
      ],
      "metadata": {
        "id": "VFBlqUW5PYiE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over tokens in Doc\n",
        "for token in doc:\n",
        "  print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDIn-c1HPlLH",
        "outputId": "4f0829bd-7720-4f0c-8021-3969d0dc07fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "world\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The token object\n",
        "# Index into the Doc to get a single token\n",
        "token = doc[1]"
      ],
      "metadata": {
        "id": "KQpRoUdPPzCf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ_P0vT7P6yO",
        "outputId": "2f09f435-eba7-4510-e857-14057184f941"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The span object\n",
        "# A slice from the Doc is a span object\n",
        "span = doc[1:3]\n",
        "print(span.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQlxCG8IP75m",
        "outputId": "8fa0c167-96a3-42f9-8e5a-fab7fa25f1f4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "world!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lexical attributes\n",
        "doc = nlp(\"It costs $5.\")\n",
        "print(f\"Index: {[token.i for token in doc]}\")\n",
        "print(f\"Text: {[token.text for token in doc]}\")\n",
        "\n",
        "print(f\"is_alpha: {[token.is_alpha for token in doc]}\")\n",
        "print(f\"is_punct: {[token.is_punct for token in doc]}\")\n",
        "print(f\"like_num: {[token.like_num for token in doc]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da16541aQRO6",
        "outputId": "75879327-7402-433c-db3f-c3fcb5af0314"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: [0, 1, 2, 3, 4]\n",
            "Text: ['It', 'costs', '$', '5', '.']\n",
            "is_alpha: [True, True, False, False, False]\n",
            "is_punct: [False, False, False, False, True]\n",
            "like_num: [False, False, False, True, False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Documents, spans and tokens"
      ],
      "metadata": {
        "id": "-RhXuUdUQcl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When calling `nlp` on a string, SpaCy first tokenizes the text and creates a document object. In this excercise, we'll lean more about the `Doc`, as well as its views `Token` and `Span`."
      ],
      "metadata": {
        "id": "HpjQUMcNRxSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# preprocess text\n",
        "doc = nlp(\"I like tree kangaroos and narwhals\")\n",
        "\n",
        "# Select the first token\n",
        "first_token = doc[0]\n",
        "\n",
        "# Print the firs token's text\n",
        "print(first_token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvxcXo7xmItI",
        "outputId": "3e012567-e81b-4c42-9321-a4771977ba44"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Lexical attributes\n",
        "\n",
        "Look for two subsequent tokens: a number and a percent sign"
      ],
      "metadata": {
        "id": "PqH-zwD2mmAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the text\n",
        "doc = nlp(\n",
        "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
        "    \"Now less than 4% are.\"\n",
        ")\n",
        "\n",
        "for token in doc:\n",
        "  if token.like_num:\n",
        "    next_token = doc[token.i + 1]\n",
        "    if next_token.text == \"%\":\n",
        "      print(f\"Percentage found: {token.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPdOdV7dnlua",
        "outputId": "3a4d34a3-b602-482b-b871-282709c60c7e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage found: 60\n",
            "Percentage found: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Trained pipelines\n",
        "\n",
        "**What are trained pipelines?**\n",
        "\n",
        "* Models that enable spaCy to predit linguistic attributes in context\n",
        "  * Part-of-Speech tags\n",
        "  * Syntactic dependencies\n",
        "  * Named entities\n",
        "\n",
        "* Trained on labeled example tasks\n",
        "* Can be updated with more examples to fine-tune predictions"
      ],
      "metadata": {
        "id": "79Xcr_mtn1Lt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Loading Pipelines\n",
        "\n",
        "The pipelines used in this course are already pre-installed. For this more details on spaCy's trained pipelines and how to install them on your machine, see the [documentation](https://spacy.io/usage/models)."
      ],
      "metadata": {
        "id": "OkEKhaNtoboD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading small english pipeline\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "print(doc.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsJe0c9rqBEp",
        "outputId": "0ff3413e-904f-404d-878c-88addca9f0a0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Predicting linguistic annotations\n",
        "\n",
        "Now let's try one of spaCy's trained pipeline packages and see its predictions in action."
      ],
      "metadata": {
        "id": "X3QqedguqPcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "  token_text = token.text\n",
        "  token_pos = token.pos_\n",
        "  token_dep = token.dep_\n",
        "\n",
        "  print(f\"Token text: {token_text:<12}, POS: {token_pos:<10}, Dependency: {token_dep}\")\n",
        "  print(f\"Dependency expalination: {spacy.explain(token_dep)}\")\n",
        "  print(f\"POS explaination: {spacy.explain(token_pos)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVnOkxg7qiZZ",
        "outputId": "b571efd9-e315-4c6e-8394-5ef92c588584"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token text: It          , POS: PRON      , Dependency: nsubj\n",
            "Dependency expalination: nominal subject\n",
            "POS explaination: pronoun\n",
            "\n",
            "Token text: ’s          , POS: VERB      , Dependency: punct\n",
            "Dependency expalination: punctuation\n",
            "POS explaination: verb\n",
            "\n",
            "Token text: official    , POS: NOUN      , Dependency: ccomp\n",
            "Dependency expalination: clausal complement\n",
            "POS explaination: noun\n",
            "\n",
            "Token text: :           , POS: PUNCT     , Dependency: punct\n",
            "Dependency expalination: punctuation\n",
            "POS explaination: punctuation\n",
            "\n",
            "Token text: Apple       , POS: PROPN     , Dependency: nsubj\n",
            "Dependency expalination: nominal subject\n",
            "POS explaination: proper noun\n",
            "\n",
            "Token text: is          , POS: AUX       , Dependency: ROOT\n",
            "Dependency expalination: None\n",
            "POS explaination: auxiliary\n",
            "\n",
            "Token text: the         , POS: DET       , Dependency: det\n",
            "Dependency expalination: determiner\n",
            "POS explaination: determiner\n",
            "\n",
            "Token text: first       , POS: ADJ       , Dependency: amod\n",
            "Dependency expalination: adjectival modifier\n",
            "POS explaination: adjective\n",
            "\n",
            "Token text: U.S.        , POS: PROPN     , Dependency: nmod\n",
            "Dependency expalination: modifier of nominal\n",
            "POS explaination: proper noun\n",
            "\n",
            "Token text: public      , POS: ADJ       , Dependency: amod\n",
            "Dependency expalination: adjectival modifier\n",
            "POS explaination: adjective\n",
            "\n",
            "Token text: company     , POS: NOUN      , Dependency: attr\n",
            "Dependency expalination: attribute\n",
            "POS explaination: noun\n",
            "\n",
            "Token text: to          , POS: PART      , Dependency: aux\n",
            "Dependency expalination: auxiliary\n",
            "POS explaination: particle\n",
            "\n",
            "Token text: reach       , POS: VERB      , Dependency: relcl\n",
            "Dependency expalination: relative clause modifier\n",
            "POS explaination: verb\n",
            "\n",
            "Token text: a           , POS: DET       , Dependency: det\n",
            "Dependency expalination: determiner\n",
            "POS explaination: determiner\n",
            "\n",
            "Token text: $           , POS: SYM       , Dependency: quantmod\n",
            "Dependency expalination: modifier of quantifier\n",
            "POS explaination: symbol\n",
            "\n",
            "Token text: 1           , POS: NUM       , Dependency: compound\n",
            "Dependency expalination: compound\n",
            "POS explaination: numeral\n",
            "\n",
            "Token text: trillion    , POS: NUM       , Dependency: nummod\n",
            "Dependency expalination: numeric modifier\n",
            "POS explaination: numeral\n",
            "\n",
            "Token text: market      , POS: NOUN      , Dependency: compound\n",
            "Dependency expalination: compound\n",
            "POS explaination: noun\n",
            "\n",
            "Token text: value       , POS: NOUN      , Dependency: dobj\n",
            "Dependency expalination: direct object\n",
            "POS explaination: noun\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the docs to print label_ attribute\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
        "\n",
        "# process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterate over the predicted entities\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5eH0cPFq_be",
        "outputId": "c0bbc2d6-2e81-4323-f79b-00c1b22b869d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple ORG\n",
            "first ORDINAL\n",
            "U.S. GPE\n",
            "$1 trillion MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Predicting named entities in context\n",
        "\n",
        "Models are staistical and not always right. Whether the predictions are correct depends on the training data and the text preprocessed. Let's take a look at an example."
      ],
      "metadata": {
        "id": "qgIOIv8DsL4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterate over the entities\n",
        "for ent in doc.ents:\n",
        "    # Print the entity text and label\n",
        "    print(ent.text, ent.label_)\n",
        "\n",
        "# Get the span for \"iPhone X\"\n",
        "iphone_x = doc[1:3]\n",
        "\n",
        "# Print the span text\n",
        "print(\"Missing entity:\", iphone_x.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhSEMVpZtRL_",
        "outputId": "3c4f595d-6904-444b-94e5-14b624f6de14"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple ORG\n",
            "Missing entity: iPhone X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Rule-based matching\n",
        "\n",
        "**Why not just regular expressions?**\n",
        "\n",
        "* Match on `Doc` objects, not just strings\n",
        "* Match on tokens and token attributes\n",
        "* Use a model's predictions\n",
        "* Example: \"duck\"(verb) vs \"duck\"(noun)"
      ],
      "metadata": {
        "id": "Gih6YqfptrBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 Using the Matcher"
      ],
      "metadata": {
        "id": "4Z5_LKKEt22K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Upcoming iPhone X release date leaked as Apple reveals pre-orders\")\n",
        "\n",
        "# Intitialize the Matcher with the shared vocabulary\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Create a pattern matching two tokens\n",
        "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
        "\n",
        "# Add pattern to the matcher\n",
        "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
        "\n",
        "# Use the matcher on the doc\n",
        "matches = matcher(doc)\n",
        "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csGFF12t08Fr",
        "outputId": "6b4feeb4-3f8a-45ab-dea0-830a6db4aa41"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches: ['iPhone X']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 Writing match patterns\n",
        "\n"
      ],
      "metadata": {
        "id": "gkLOdWsJ0-vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\n",
        "    \"After making the iOS update you won't notice a radical system-wide \"\n",
        "    \"redesign: nothing like the aesthetic upheaval we got with iOS 7. Most of \"\n",
        "    \"iOS 11's furniture remains the same as in iOS 10. But you will discover \"\n",
        "    \"some tweaks once you delve a little deeper.\"\n",
        ")\n",
        "\n",
        "# Writing a pattern for full ios versions\n",
        "pattern = [{\"TEXT\": \"iOS\"}, {\"IS_DIGIT\": True}]\n",
        "\n",
        "# Add the patterns to the matcher\n",
        "matcher.add(\"IOS_VERSION_PATTERN\", [pattern])\n",
        "\n",
        "# use the matcher on the doc\n",
        "matches = matcher(doc)\n",
        "print(\"Total matches found:\", len(matches))\n",
        "\n",
        "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvVDs6FJ1HZM",
        "outputId": "1c851b2a-8183-483c-ec94-0b28f82aecd1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total matches found: 3\n",
            "Matches: ['iOS 7', 'iOS 11', 'iOS 10']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\n",
        "    \"i downloaded Fortnite on my laptop and can't open the game at all. Help? \"\n",
        "    \"so when I was downloading Minecraft, I got the Windows version where it \"\n",
        "    \"is the '.zip' folder and I used the default program to unpack it... do \"\n",
        "    \"I also need to download Winzip?\"\n",
        ")\n",
        "\n",
        "# Write a pattern that matches a form of \"download\" plus proper noun\n",
        "pattern = [{\"LEMMA\": \"download\"}, {\"POS\": \"PROPN\"}]\n",
        "\n",
        "# Add the pattern to the matcher and apply the matcher to the doc\n",
        "matcher.add(\"DOWNLOAD_THINGS_PATTERN\", [pattern])\n",
        "matches = matcher(doc)\n",
        "print(\"Total matches found:\", len(matches))\n",
        "\n",
        "# Iterate over the matches and print the span text\n",
        "for match_id, start, end in matches:\n",
        "    print(\"Match found:\", doc[start:end].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24oE8JKb3URm",
        "outputId": "f32f3a86-ab60-4acc-876e-e985387f3c47"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total matches found: 3\n",
            "Match found: downloaded Fortnite\n",
            "Match found: downloading Minecraft\n",
            "Match found: download Winzip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\n",
        "    \"Features of the app include a beautiful design, smart search, automatic \"\n",
        "    \"labels and optional voice responses.\"\n",
        ")\n",
        "\n",
        "# Patter for adjective plus one or two noun\n",
        "pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}]\n",
        "\n",
        "# Add the pattern to the macher\n",
        "matcher.add(\"ADJ_NOUN_PATTERN\", [pattern])\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Iterate over the matches and print span text\n",
        "for match_id, start, end in matches:\n",
        "  print(f\"Match found: {doc[start:end]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s86t3w-g5MHI",
        "outputId": "80ccecfb-44e4-43d8-e95a-604880154548"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match found: beautiful design\n",
            "Match found: smart search\n",
            "Match found: automatic labels\n",
            "Match found: optional voice\n",
            "Match found: optional voice responses\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IIsUd6K358jI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}